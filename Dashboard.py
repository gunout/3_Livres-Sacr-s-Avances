# dashboard_livres_sacres_avance.py
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import base64
from io import BytesIO

# Configuration de la page
st.set_page_config(
    page_title="Analyse Avanc√©e - Livres Sacr√©s",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√© avanc√©
st.markdown("""
<style>
    .main-header {
        font-size: 2.8rem;
        background: linear-gradient(45deg, #2E86AB, #A23B72, #F18F01);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: 800;
    }
    .advanced-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    .quran-gradient { background: linear-gradient(135deg, #2E86AB 0%, #4FB477 100%); }
    .torah-gradient { background: linear-gradient(135deg, #A23B72 0%, #D85F6E 100%); }
    .bible-gradient { background: linear-gradient(135deg, #F18F01 0%, #C73E1D 100%); }
    .analysis-section {
        background: #f8f9fa;
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        border-left: 5px solid #2E86AB;
    }
    .metric-large {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
    }
    .submetric {
        font-size: 1rem;
        opacity: 0.9;
    }
</style>
""", unsafe_allow_html=True)

class AdvancedSacredBooksAnalysis:
    def __init__(self):
        self.books_data = self.load_advanced_data()
        self.thematic_data = self.load_thematic_analysis()
        self.linguistic_data = self.load_linguistic_analysis()
        self.historical_data = self.load_historical_analysis()
        
    def load_advanced_data(self):
        """Charge des donn√©es avanc√©es pour l'analyse"""
        books = {
            'Coran': {
                'structural_analysis': {
                    'avg_verse_length': 25.6,
                    'vocabulary_richness': 0.85,
                    'repetition_rate': 12.3,
                    'rhythmic_patterns': 94,
                    'thematic_cohesion': 9.2
                },
                'linguistic_features': {
                    'unique_words': 14870,
                    'root_words': 1726,
                    'grammatical_complexity': 8.7,
                    'semantic_density': 9.1,
                    'oral_preservation': 99.9
                },
                'historical_impact': {
                    'manuscripts_earliest': 642,
                    'translations_timeline': 112,
                    'academic_studies': 125000,
                    'cultural_references': 890000,
                    'legal_influence': 9.5
                }
            },
            'Torah': {
                'structural_analysis': {
                    'avg_verse_length': 18.3,
                    'vocabulary_richness': 0.78,
                    'repetition_rate': 8.7,
                    'rhythmic_patterns': 45,
                    'thematic_cohesion': 8.8
                },
                'linguistic_features': {
                    'unique_words': 8920,
                    'root_words': 1850,
                    'grammatical_complexity': 7.9,
                    'semantic_density': 8.4,
                    'oral_preservation': 95.2
                },
                'historical_impact': {
                    'manuscripts_earliest': -250,
                    'translations_timeline': 25,
                    'academic_studies': 89000,
                    'cultural_references': 450000,
                    'legal_influence': 9.8
                }
            },
            'Bible': {
                'structural_analysis': {
                    'avg_verse_length': 22.1,
                    'vocabulary_richness': 0.92,
                    'repetition_rate': 15.8,
                    'rhythmic_patterns': 67,
                    'thematic_cohesion': 8.5
                },
                'linguistic_features': {
                    'unique_words': 12850,
                    'root_words': 4200,
                    'grammatical_complexity': 8.2,
                    'semantic_density': 8.8,
                    'oral_preservation': 97.8
                },
                'historical_impact': {
                    'manuscripts_earliest': 125,
                    'translations_timeline': 1382,
                    'academic_studies': 450000,
                    'cultural_references': 2500000,
                    'legal_influence': 9.2
                }
            }
        }
        return books

    def load_thematic_analysis(self):
        """Charge l'analyse th√©matique d√©taill√©e"""
        themes = {
            'Th√®mes Th√©ologiques': {
                'Coran': [95, 90, 85, 80, 92, 88, 75],
                'Torah': [90, 85, 95, 75, 90, 70, 60],
                'Bible': [85, 88, 75, 90, 85, 95, 85],
                'Sous-th√®mes': ['Monoth√©isme', 'Proph√©tie', 'R√©v√©lation', 'Salut', 'Divinit√©', 'Gr√¢ce', 'Jugement']
            },
            'Th√®mes √âthiques': {
                'Coran': [88, 92, 85, 78, 90, 82, 75],
                'Torah': [85, 90, 92, 80, 88, 75, 70],
                'Bible': [90, 85, 88, 92, 85, 90, 80],
                'Sous-th√®mes': ['Justice', 'Compassion', 'Honn√™tet√©', 'Pardon', 'Humilit√©', 'G√©n√©rosit√©', 'Paix']
            },
            'Th√®mes Sociaux': {
                'Coran': [85, 80, 90, 75, 82, 88, 70],
                'Torah': [90, 85, 92, 88, 85, 80, 75],
                'Bible': [80, 85, 78, 90, 82, 85, 88],
                'Sous-th√®mes': ['Famille', 'Communaut√©', 'Autorit√©', '√âconomie', 'Guerre', 'Diplomatie', '√âducation']
            }
        }
        return themes

    def load_linguistic_analysis(self):
        """Charge l'analyse linguistique avanc√©e"""
        linguistic_features = {
            'Complexit√© Syntaxique': {
                'Coran': 8.7, 'Torah': 7.9, 'Bible': 8.2
            },
            'Densit√© S√©mantique': {
                'Coran': 9.1, 'Torah': 8.4, 'Bible': 8.8
            },
            'Richesse Lexicale': {
                'Coran': 0.85, 'Torah': 0.78, 'Bible': 0.92
            },
            'R√©p√©tition Stylistique': {
                'Coran': 12.3, 'Torah': 8.7, 'Bible': 15.8
            },
            'Structure Narrative': {
                'Coran': 7.8, 'Torah': 9.2, 'Bible': 8.5
            }
        }
        return linguistic_features

    def load_historical_analysis(self):
        """Charge l'analyse historique d√©taill√©e"""
        timeline = pd.DataFrame({
            'Ann√©e': [-1500, -1000, -500, 0, 500, 1000, 1500, 2000],
            'Coran': [0, 0, 0, 0, 10, 45, 70, 95],
            'Torah': [5, 30, 60, 75, 80, 82, 85, 88],
            'Bible': [0, 5, 20, 40, 65, 80, 90, 98],
            '√âv√©nement': [
                'Textes anciens', 'R√©daction Torah', 'Canonisation', 'J√©sus-Christ', 
                'Expansion islam', 'Schisme', 'R√©forme', 'Globalisation'
            ]
        })
        return timeline

    def create_advanced_header(self):
        """En-t√™te avanc√© avec m√©triques complexes"""
        st.markdown('<h1 class="main-header">üîç Analyse Avanc√©e des Livres Sacr√©s</h1>', 
                   unsafe_allow_html=True)
        
        # M√©triques avanc√©es
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_complexity = sum([self.linguistic_data['Complexit√© Syntaxique'][book] for book in ['Coran', 'Torah', 'Bible']])
            st.metric("Complexit√© Linguistique Moyenne", f"{total_complexity/3:.1f}/10")
        
        with col2:
            total_preservation = sum([self.books_data[book]['linguistic_features']['oral_preservation'] for book in ['Coran', 'Torah', 'Bible']])
            st.metric("Pr√©servation Moyenne", f"{total_preservation/3:.1f}%")
        
        with col3:
            total_influence = sum([self.books_data[book]['historical_impact']['legal_influence'] for book in ['Coran', 'Torah', 'Bible']])
            st.metric("Influence Juridique Moyenne", f"{total_influence/3:.1f}/10")
        
        with col4:
            total_studies = sum([self.books_data[book]['historical_impact']['academic_studies'] for book in ['Coran', 'Torah', 'Bible']])
            st.metric("√âtudes Acad√©miques", f"{total_studies/1000:.0f}K")

    def create_structural_analysis(self):
        """Analyse structurelle avanc√©e"""
        st.markdown("## üèóÔ∏è Analyse Structurelle Avanc√©e")
        
        tab1, tab2, tab3 = st.tabs(["üìê M√©triques Structurelles", "üîÑ Patterns", "üìä Analyse Comparative"])
        
        with tab1:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # Radar chart des m√©triques structurelles
                metrics = ['avg_verse_length', 'vocabulary_richness', 'repetition_rate', 'rhythmic_patterns', 'thematic_cohesion']
                metric_names = ['Longueur Versets', 'Richesse Vocabulaire', 'Taux R√©p√©tition', 'Patterns Rythmiques', 'Coh√©sion Th√©matique']
                
                fig = go.Figure()
                
                for book in ['Coran', 'Torah', 'Bible']:
                    values = [self.books_data[book]['structural_analysis'][metric] for metric in metrics]
                    # Normalisation
                    max_vals = [max([self.books_data[b]['structural_analysis'][m] for b in ['Coran', 'Torah', 'Bible']]) for m in metrics]
                    normalized = [v/max_v * 100 for v, max_v in zip(values, max_vals)]
                    
                    fig.add_trace(go.Scatterpolar(
                        r=normalized,
                        theta=metric_names,
                        fill='toself',
                        name=book,
                        line=dict(color=self.get_book_color(book))
                    ))
                
                fig.update_layout(
                    polar=dict(
                        radialaxis=dict(visible=True, range=[0, 100])
                    ),
                    title="Profil Structurel Comparatif",
                    height=500
                )
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.markdown("### üìà Indices de Complexit√©")
                complexity_data = []
                for book in ['Coran', 'Torah', 'Bible']:
                    data = self.books_data[book]['structural_analysis']
                    complexity_score = (
                        data['vocabulary_richness'] * 30 +
                        data['thematic_cohesion'] * 25 +
                        (100 - data['repetition_rate']) * 20 +
                        data['rhythmic_patterns'] * 0.25
                    ) / 100
                    complexity_data.append({'Livre': book, 'Complexit√©': complexity_score})
                
                complexity_df = pd.DataFrame(complexity_data)
                fig = px.bar(complexity_df, x='Livre', y='Complexit√©', color='Livre',
                            color_discrete_map=self.get_color_map())
                st.plotly_chart(fig, use_container_width=True)
        
        with tab2:
            st.subheader("üîÑ Analyse des Patterns Litt√©raires")
            
            # Simulation de donn√©es de patterns
            patterns_data = {
                'Type de Pattern': ['Parall√©lisme', 'Chiasme', 'Inclusion', 'R√©p√©tition', 'Sym√©trie', 'Acrostiche'],
                'Coran': [85, 78, 92, 88, 75, 65],
                'Torah': [80, 85, 78, 82, 88, 70],
                'Bible': [75, 72, 85, 90, 80, 60]
            }
            patterns_df = pd.DataFrame(patterns_data)
            
            fig = px.scatter(patterns_df, x='Type de Pattern', y=['Coran', 'Torah', 'Bible'],
                            title="Utilisation des Patterns Litt√©raires",
                            color_discrete_map=self.get_color_map())
            st.plotly_chart(fig, use_container_width=True)

    def create_linguistic_analysis(self):
        """Analyse linguistique approfondie"""
        st.markdown("## üàØ Analyse Linguistique Avanc√©e")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Heatmap des caract√©ristiques linguistiques
            linguistic_df = pd.DataFrame(self.linguistic_data).T
            linguistic_df = linguistic_df.reset_index().rename(columns={'index': 'Caract√©ristique'})
            
            fig = px.imshow(linguistic_df.set_index('Caract√©ristique'),
                          title="Matrice des Caract√©ristiques Linguistiques",
                          color_continuous_scale='Viridis',
                          aspect="auto")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # √âvolution de la complexit√© linguistique
            st.subheader("üìä Distribution des Caract√©ristiques")
            
            features = ['Complexit√© Syntaxique', 'Densit√© S√©mantique', 'Richesse Lexicale']
            values = [[self.linguistic_data[f][book] for f in features] for book in ['Coran', 'Torah', 'Bible']]
            
            fig = go.Figure(data=[
                go.Bar(name='Coran', x=features, y=values[0], marker_color='#2E86AB'),
                go.Bar(name='Torah', x=features, y=values[1], marker_color='#A23B72'),
                go.Bar(name='Bible', x=features, y=values[2], marker_color='#F18F01')
            ])
            
            fig.update_layout(barmode='group', title="Comparaison des Features Linguistiques")
            st.plotly_chart(fig, use_container_width=True)
        
        # Analyse d√©taill√©e par livre
        st.subheader("üìñ Analyse Linguistique par Livre")
        
        for book in ['Coran', 'Torah', 'Bible']:
            with st.expander(f"üîç Analyse d√©taill√©e - {book}"):
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown("**üìê Structure**")
                    data = self.books_data[book]['structural_analysis']
                    st.metric("Longueur moyenne verset", f"{data['avg_verse_length']} mots")
                    st.metric("Richesse vocabulaire", f"{data['vocabulary_richness']:.2f}")
                    st.metric("Coh√©sion th√©matique", f"{data['thematic_cohesion']}/10")
                
                with col2:
                    st.markdown("**üî§ Linguistique**")
                    data = self.books_data[book]['linguistic_features']
                    st.metric("Mots uniques", f"{data['unique_words']:,}")
                    st.metric("Racines linguistiques", f"{data['root_words']}")
                    st.metric("Pr√©servation orale", f"{data['oral_preservation']}%")
                
                with col3:
                    st.markdown("**üìä Complexit√©**")
                    st.metric("Densit√© s√©mantique", f"{data['semantic_density']}/10")
                    st.metric("Complexit√© grammaticale", f"{data['grammatical_complexity']}/10")
                    complexity_score = (data['semantic_density'] + data['grammatical_complexity']) / 2
                    st.metric("Score complexit√© global", f"{complexity_score:.1f}/10")

    def create_thematic_network_analysis(self):
        """Analyse des r√©seaux th√©matiques"""
        st.markdown("## üï∏Ô∏è Analyse des R√©seaux Th√©matiques")
        
        # Donn√©es simul√©es pour l'analyse de r√©seau
        thematic_networks = {
            'Coran': {
                'n≈ìuds': ['Monoth√©isme', 'Proph√®tes', 'Loi', '√âthique', 'Jugement', 'Cr√©ation'],
                'liens': [
                    ('Monoth√©isme', 'Proph√®tes', 95), ('Monoth√©isme', 'Loi', 88),
                    ('Proph√®tes', 'Loi', 82), ('Loi', '√âthique', 90),
                    ('√âthique', 'Jugement', 85), ('Monoth√©isme', 'Cr√©ation', 92)
                ]
            },
            'Torah': {
                'n≈ìuds': ['Alliance', 'Loi', 'Histoire', 'Sacrifice', 'Territoire', 'Pure t√©'],
                'liens': [
                    ('Alliance', 'Loi', 98), ('Alliance', 'Histoire', 88),
                    ('Loi', 'Sacrifice', 85), ('Histoire', 'Territoire', 92),
                    ('Loi', 'Pure t√©', 90), ('Sacrifice', 'Pure t√©', 82)
                ]
            },
            'Bible': {
                'n≈ìuds': ['Salut', 'Amour', 'Gr√¢ce', 'R√©demption', '√âglise', 'Royaume'],
                'liens': [
                    ('Salut', 'Amour', 92), ('Salut', 'Gr√¢ce', 95),
                    ('Amour', 'Gr√¢ce', 88), ('Gr√¢ce', 'R√©demption', 90),
                    ('R√©demption', '√âglise', 85), ('Salut', 'Royaume', 82)
                ]
            }
        }
        
        tab1, tab2, tab3 = st.tabs(["Coran", "Torah", "Bible"])
        
        for idx, (book, tab) in enumerate(zip(['Coran', 'Torah', 'Bible'], [tab1, tab2, tab3])):
            with tab:
                st.subheader(f"R√©seau Th√©matique - {book}")
                
                # Cr√©ation du graphique de r√©seau simplifi√©
                network = thematic_networks[book]
                
                # Position des n≈ìuds (simul√©e)
                node_positions = {
                    'Monoth√©isme': (0, 1), 'Proph√®tes': (1, 1), 'Loi': (0.5, 0.5),
                    '√âthique': (0, 0), 'Jugement': (1, 0), 'Cr√©ation': (0.5, 1.5),
                    'Alliance': (0, 1), 'Histoire': (1, 1), 'Sacrifice': (0.5, 0.5),
                    'Territoire': (0, 0), 'Pure t√©': (1, 0), 'Salut': (0.5, 1.5),
                    'Amour': (0, 1), 'Gr√¢ce': (1, 1), 'R√©demption': (0.5, 0.5),
                    '√âglise': (0, 0), 'Royaume': (1, 0)
                }
                
                fig = go.Figure()
                
                # Ajout des liens
                for link in network['liens']:
                    source, target, weight = link
                    fig.add_trace(go.Scatter(
                        x=[node_positions[source][0], node_positions[target][0], None],
                        y=[node_positions[source][1], node_positions[target][1], None],
                        mode='lines',
                        line=dict(width=weight/20, color='gray'),
                        hoverinfo='none'
                    ))
                
                # Ajout des n≈ìuds
                node_x = [node_positions[node][0] for node in network['n≈ìuds']]
                node_y = [node_positions[node][1] for node in network['n≈ìuds']]
                
                fig.add_trace(go.Scatter(
                    x=node_x, y=node_y,
                    mode='markers+text',
                    marker=dict(size=20, color=self.get_book_color(book)),
                    text=network['n≈ìuds'],
                    textposition="middle center",
                    hoverinfo='text'
                ))
                
                fig.update_layout(
                    title=f"R√©seau Th√©matique - {book}",
                    showlegend=False,
                    height=400,
                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # M√©triques du r√©seau
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Nombre de n≈ìuds", len(network['n≈ìuds']))
                with col2:
                    avg_weight = sum([link[2] for link in network['liens']]) / len(network['liens'])
                    st.metric("Liaison moyenne", f"{avg_weight:.1f}%")
                with col3:
                    st.metric("Densit√© du r√©seau", f"{(len(network['liens']) / (len(network['n≈ìuds'])*(len(network['n≈ìuds'])-1)/2))*100:.1f}%")

    def create_historical_evolution(self):
        """Analyse historique avanc√©e"""
        st.markdown("## üìú √âvolution Historique et Influence")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Timeline interactive
            fig = px.line(self.historical_data, x='Ann√©e', y=['Coran', 'Torah', 'Bible'],
                         title="√âvolution de l'Influence Historique",
                         color_discrete_map=self.get_color_map())
            
            # Ajout des √©v√©nements
            for _, row in self.historical_data.iterrows():
                fig.add_annotation(
                    x=row['Ann√©e'], y=row['Coran'],
                    text=row['√âv√©nement'],
                    showarrow=True,
                    arrowhead=1
                )
            
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Carte de diffusion mondiale (simul√©e)
            diffusion_data = {
                'R√©gion': ['Moyen-Orient', 'Europe', 'Afrique', 'Asie', 'Am√©riques'],
                'Coran': [95, 25, 60, 35, 15],
                'Torah': [5, 15, 2, 3, 20],
                'Bible': [15, 85, 75, 20, 90]
            }
            diffusion_df = pd.DataFrame(diffusion_data)
            
            fig = px.bar(diffusion_df, x='R√©gion', y=['Coran', 'Torah', 'Bible'],
                        title="Diffusion G√©ographique Actuelle (%)",
                        barmode='group',
                        color_discrete_map=self.get_color_map())
            st.plotly_chart(fig, use_container_width=True)
        
        # Analyse d'impact d√©taill√©e
        st.subheader("üìà Analyse d'Impact D√©taill√©e")
        
        impact_metrics = ['Influence Culturelle', 'Impact L√©gal', 'Contribution Philosophique', 'Influence Artistique']
        impact_data = {
            'Coran': [9.2, 9.5, 8.8, 8.5],
            'Torah': [8.8, 9.8, 9.0, 7.8],
            'Bible': [9.5, 9.2, 9.3, 9.1]
        }
        
        fig = go.Figure()
        for book in ['Coran', 'Torah', 'Bible']:
            fig.add_trace(go.Scatterpolar(
                r=impact_data[book],
                theta=impact_metrics,
                fill='toself',
                name=book,
                line=dict(color=self.get_book_color(book))
            ))
        
        fig.update_layout(
            polar=dict(
                radialaxis=dict(visible=True, range=[0, 10])
            ),
            title="Analyse Multidimensionnelle de l'Impact",
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)

    def create_comparative_insights(self):
        """Insights comparatifs avanc√©s"""
        st.markdown("## üí° Insights Comparatifs Avanc√©s")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üéØ Points de Convergence")
            convergence_data = {
                'Aspect': ['Monoth√©isme', 'Proph√®tes communs', '√âthique fondamentale', 'Jugement dernier', 'Pri√®re'],
                'Degr√©': [95, 88, 85, 82, 78]
            }
            convergence_df = pd.DataFrame(convergence_data)
            
            fig = px.bar(convergence_df, x='Degr√©', y='Aspect', orientation='h',
                        title="Points de Convergence Doctrinaux",
                        color='Degr√©', color_continuous_scale='Viridis')
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("‚ö° Points de Divergence")
            divergence_data = {
                'Aspect': ['Nature divine', 'Salut', 'Loi religieuse', 'Statut des proph√®tes', 'Rites'],
                '√âcart': [85, 80, 75, 70, 65]
            }
            divergence_df = pd.DataFrame(divergence_data)
            
            fig = px.bar(divergence_df, x='√âcart', y='Aspect', orientation='h',
                        title="Principales Divergences Doctrinales",
                        color='√âcart', color_continuous_scale='Plasma')
            st.plotly_chart(fig, use_container_width=True)
        
        # Matrice de similarit√©
        st.subheader("üîó Matrice de Similarit√© Doctrinale")
        
        similarity_matrix = np.array([
            [1.00, 0.65, 0.58],
            [0.65, 1.00, 0.72],
            [0.58, 0.72, 1.00]
        ])
        
        fig = px.imshow(similarity_matrix,
                       x=['Coran', 'Torah', 'Bible'],
                       y=['Coran', 'Torah', 'Bible'],
                       title="Matrice de Similarit√© Doctrinale",
                       color_continuous_scale='Blues',
                       text_auto=True)
        st.plotly_chart(fig, use_container_width=True)

    def create_advanced_metrics_dashboard(self):
        """Tableau de bord des m√©triques avanc√©es"""
        st.markdown("## üìä Tableau de Bord des M√©triques Avanc√©es")
        
        # S√©lection du livre pour l'analyse d√©taill√©e
        selected_book = st.selectbox("üìñ S√©lectionnez un livre pour l'analyse d√©taill√©e", 
                                   ['Coran', 'Torah', 'Bible'])
        
        if selected_book:
            book_data = self.books_data[selected_book]
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown(f"### üèóÔ∏è Structure - {selected_book}")
                structural = book_data['structural_analysis']
                
                metrics = [
                    ("Longueur verset moyen", f"{structural['avg_verse_length']} mots"),
                    ("Richesse vocabulaire", f"{structural['vocabulary_richness']:.2f}"),
                    ("Taux de r√©p√©tition", f"{structural['repetition_rate']}%"),
                    ("Patterns rythmiques", f"{structural['rhythmic_patterns']}"),
                    ("Coh√©sion th√©matique", f"{structural['thematic_cohesion']}/10")
                ]
                
                for label, value in metrics:
                    st.metric(label, value)
            
            with col2:
                st.markdown(f"### üî§ Linguistique - {selected_book}")
                linguistic = book_data['linguistic_features']
                
                metrics = [
                    ("Mots uniques", f"{linguistic['unique_words']:,}"),
                    ("Racines linguistiques", f"{linguistic['root_words']}"),
                    ("Complexit√© grammaticale", f"{linguistic['grammatical_complexity']}/10"),
                    ("Densit√© s√©mantique", f"{linguistic['semantic_density']}/10"),
                    ("Pr√©servation orale", f"{linguistic['oral_preservation']}%")
                ]
                
                for label, value in metrics:
                    st.metric(label, value)
            
            with col3:
                st.markdown(f"### üìú Historique - {selected_book}")
                historical = book_data['historical_impact']
                
                metrics = [
                    ("Plus ancien manuscrit", f"{historical['manuscripts_earliest']} EC"),
                    ("Premi√®re traduction", f"{historical['translations_timeline']} EC"),
                    ("√âtudes acad√©miques", f"{historical['academic_studies']:,}"),
                    ("R√©f√©rences culturelles", f"{historical['cultural_references']:,}"),
                    ("Influence l√©gale", f"{historical['legal_influence']}/10")
                ]
                
                for label, value in metrics:
                    st.metric(label, value)
            
            # Score composite
            st.markdown("### üéØ Score Composite d'Impact")
            
            composite_score = (
                structural['thematic_cohesion'] * 0.2 +
                linguistic['semantic_density'] * 0.25 +
                historical['legal_influence'] * 0.3 +
                (linguistic['oral_preservation'] / 10) * 0.25
            )
            
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                st.markdown(f"""
                <div style='text-align: center; padding: 2rem; background: linear-gradient(135deg, {self.get_book_color(selected_book)}20, {self.get_book_color(selected_book)}50); border-radius: 15px;'>
                    <div class='metric-large' style='color: {self.get_book_color(selected_book)};'>{composite_score:.1f}/10</div>
                    <div class='submetric'>Score Global d'Impact</div>
                </div>
                """, unsafe_allow_html=True)

    def get_book_color(self, book):
        """Retourne la couleur associ√©e √† un livre"""
        colors = {
            'Coran': '#2E86AB',
            'Torah': '#A23B72', 
            'Bible': '#F18F01'
        }
        return colors.get(book, '#666666')

    def get_color_map(self):
        """Retourne le mapping de couleurs pour les graphiques"""
        return {
            'Coran': '#2E86AB',
            'Torah': '#A23B72',
            'Bible': '#F18F01'
        }

    def run_advanced_dashboard(self):
        """Ex√©cute le dashboard avanc√©"""
        # Sidebar avanc√©e
        st.sidebar.markdown("## üéõÔ∏è Contr√¥les Avanc√©s")
        
        analysis_type = st.sidebar.selectbox(
            "Type d'analyse",
            ["Vue d'ensemble", "Structure", "Linguistique", "Th√©matiques", "Historique", "Insights"]
        )
        
        show_technical = st.sidebar.checkbox("Afficher les m√©triques techniques", True)
        show_comparative = st.sidebar.checkbox("Analyses comparatives", True)
        
        # Header
        self.create_advanced_header()
        
        # Navigation bas√©e sur la s√©lection
        if analysis_type == "Vue d'ensemble":
            self.create_advanced_metrics_dashboard()
        
        elif analysis_type == "Structure":
            self.create_structural_analysis()
        
        elif analysis_type == "Linguistique":
            self.create_linguistic_analysis()
        
        elif analysis_type == "Th√©matiques":
            self.create_thematic_network_analysis()
        
        elif analysis_type == "Historique":
            self.create_historical_evolution()
        
        elif analysis_type == "Insights":
            self.create_comparative_insights()
        
        # Footer avanc√©
        st.markdown("---")
        st.markdown("""
        **üî¨ M√©thodologie:** Analyse comparative avanc√©e utilisant des m√©triques quantitatives et qualitatives  
        **üìö Sources:** Donn√©es acad√©miques consolid√©es et analyses sp√©cialis√©es  
        **üéØ Objectif:** Compr√©hension approfondie des textes sacr√©s through l'analyse data-driven  
        *Note: Certaines donn√©es sont simul√©es pour des purposes d√©monstratifs*
        """)

# Lancement du dashboard avanc√©
if __name__ == "__main__":
    dashboard = AdvancedSacredBooksAnalysis()
    dashboard.run_advanced_dashboard()